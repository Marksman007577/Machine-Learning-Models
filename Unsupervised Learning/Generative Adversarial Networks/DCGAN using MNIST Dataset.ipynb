{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da6fc5f1-c8f6-4156-b9df-f05fcc52ab52",
   "metadata": {},
   "source": [
    "**IMPORT RELEVANT LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d23d30e1-d4b2-43d5-810c-22ddddffeace",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Main'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time, re\n",
    "import pickle, gzip, datetime\n",
    "\n",
    "'''Data Viz'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import Grid\n",
    "from IPython.display import SVG\n",
    "%matplotlib inline\n",
    "\n",
    "'''Data Prep and Model Evaluation'''\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, mean_squared_error\n",
    "\n",
    "'''Algos'''\n",
    "import lightgbm as lgb\n",
    "\n",
    "'''TensorFlow and Keras'''\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "K = keras.backend\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Input, Lambda\n",
    "from tensorflow.keras.layers import Embedding, Flatten, dot\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, LeakyReLU, Reshape, MaxPooling2D\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2DTranspose\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0340733d-2b14-4e48-a651-dca122f6c179",
   "metadata": {},
   "source": [
    "**READ THE DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b227a055-0738-4003-a184-4fab842e2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f62b3254-d656-4b48-80c4-ab5601b5db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"C:\\\\Users\\\\User\\\\Desktop\\\\Machine Learning\\\\Machine-Learning-Models\\\\Unsupervised Learning\\\\Generative Adversarial Networks\\\\mnist_data\\mnist.pkl.gz\", mode='rb') as file_content:\n",
    "    train_set, validation_set, test_set = pickle.load(file=file_content, encoding='latin1')\n",
    "    file_content.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e4b819-500a-448f-8a22-a32356e6508e",
   "metadata": {},
   "source": [
    "**PERFORM TRAIN TEST SPLIT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "359de5df-02da-458f-a09e-1f5369ffed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Train Set'\n",
    "X_train, y_train = train_set[0], train_set[1]\n",
    "\n",
    "'Validation Set'\n",
    "X_validation, y_validation = validation_set[0], validation_set[1]\n",
    "\n",
    "'Test Set'\n",
    "X_test, y_test = test_set[0], test_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0930903-ef8a-4aa8-8b9d-5ef8d12aba8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea845e0b-af89-49ca-b180-a6a61f4ff9c4",
   "metadata": {},
   "source": [
    "**RESHAPE DATASET FOR TENSORFLOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df034ffc-fd4b-44d5-a389-72a4b7e99f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_keras = X_train.reshape(50000,28,28,1)\n",
    "X_validation_keras = X_validation.reshape(10000,28,28,1)\n",
    "X_test_keras = X_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca6cfbff-900d-43c0-92b5-3be5b918677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_keras = to_categorical(y_train)\n",
    "y_validation_keras = to_categorical(y_validation)\n",
    "y_test_keras = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e804b3ba-51c0-4849-87d5-46d7847091ff",
   "metadata": {},
   "source": [
    "**CREATE PANDAS DATAFRAME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee1b4f0d-dd58-4595-9ed9-3a2cfbddf36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = range(0, len(X_train))\n",
    "validation_index = range(len(X_train), len(X_train)+len(X_validation))\n",
    "test_index = range(len(X_train)+len(X_validation), len(X_train)+len(X_validation)+len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2dcdbeb1-7eb0-44e1-9266-26e9f0a8f70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 50000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cabfc256-8028-4a42-8f15-62fefd4d1819",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data=X_train, index=train_index)\n",
    "y_train = pd.Series(data=y_train, index=train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "626f17ed-536b-44ad-98c1-22153420844a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    ...  774  775  776  \\\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "49995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "49996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "49997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "49998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "49999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "       777  778  779  780  781  782  783  \n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "49995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "49996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "49997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "49998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "49999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[50000 rows x 784 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b67de219-af82-4df0-aca7-0b9c00753b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation = pd.DataFrame(data=X_validation, index=validation_index)\n",
    "y_validation = pd.Series(data=y_validation, index=validation_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f20020ff-07a1-4bcb-a0e6-2837e6bf50f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    ...  774  775  776  \\\n",
       "50000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "50001  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "50002  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "50003  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "50004  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "59995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "59996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "59997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "59998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "59999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "       777  778  779  780  781  782  783  \n",
       "50000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "50001  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "50002  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "50003  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "50004  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "59995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "59996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "59997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "59998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "59999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[10000 rows x 784 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d73e16cd-2c6e-442a-b4b9-e2ac8677eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(data=X_test, index=test_index)\n",
    "y_test = pd.Series(data=y_test, index=test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf15f6e4-351f-4c64-8ee3-1b3d5cb61f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    ...  774  775  776  \\\n",
       "60000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "60001  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "60002  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "60003  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "60004  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "69995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "       777  778  779  780  781  782  783  \n",
       "60000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "60001  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "60002  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "60003  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "60004  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "69995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "69996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "69997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "69998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "69999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[10000 rows x 784 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b8c370-3c91-45aa-8ba9-dbeacbf6d3c0",
   "metadata": {},
   "source": [
    "**DISPLAY A DIGIT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd0b6971-4514-4dee-87c8-a7381e3ca96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2232be8e890>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label = y_train.loc[4]\n",
    "image = X_train.loc[4,:].values.reshape([28, 28])\n",
    "plt.title(f'Index Location:{4} = Label:{label}')\n",
    "plt.imshow(image, cmap=plt.get_cmap('viridis'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6cfe60-0554-4653-8831-040f9022b93e",
   "metadata": {},
   "source": [
    "**CREATE THE CONVOLUTIONAL NEURAL NETWORK (CNN)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e4e498-3673-4b68-8b11-0790a617e63a",
   "metadata": {},
   "source": [
    "*We will call Sequential() in Keras to begin the model creation. Then, we\n",
    "will add two convolution layers, each with 32 filters of a kernel size of 5 x\n",
    "5, a default stride of 1, and a ReLU activation. Then, we perform max\n",
    "pooling with a pooling window of 2 x 2 and a stride of 1. We also perform\n",
    "dropout, which you may recall is a form of regularization to reduce\n",
    "overfitting of the neural network. Specifically, we will drop 25% of the input\n",
    "units.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbefeb65-0fa4-4585-bd21-a946f6bf16f1",
   "metadata": {},
   "source": [
    "*In the next stage, we add two convolution layers again, this time with 64\n",
    "filters of a kernel size of 3 x 3. Then, we perform max pooling with a pooling\n",
    "window of 2 x 2 and a stride of 2. And, we follow this up with a dropout\n",
    "layer, with a dropout percentage of 25%.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fac48b-3e19-4207-b830-b69b3175c701",
   "metadata": {},
   "source": [
    "*Finally, we flatten the images, add a regular neural network with 256 hidden\n",
    "units, perform dropout with a dropout percentage of 50%, and perform 10-\n",
    "class classification using the softmax function:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7aaa1cf-4f01-4edd-a18f-5f3fb002eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model graph\n",
    "model = Sequential()\n",
    "# input/first layer\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding= 'Same', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding= 'Same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# second layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding= 'Same', activation='relu'))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding= 'Same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation= 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation= 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb51af6e-db91-4f62-8ee8-40aebed744dc",
   "metadata": {},
   "source": [
    "**TRAIN THE CONVOLUTIONAL NEURAL NETWORK (CNN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040cd7f5-5447-488c-85c4-fdb4182274e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 133s 84ms/step - loss: 0.2011 - accuracy: 0.9369 - val_loss: 0.0528 - val_accuracy: 0.9846\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 128s 82ms/step - loss: 0.0762 - accuracy: 0.9774 - val_loss: 0.0389 - val_accuracy: 0.9888\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 130s 83ms/step - loss: 0.0589 - accuracy: 0.9820 - val_loss: 0.0352 - val_accuracy: 0.9895\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 135s 86ms/step - loss: 0.0425 - accuracy: 0.9873 - val_loss: 0.0316 - val_accuracy: 0.9906\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 143s 91ms/step - loss: 0.0373 - accuracy: 0.9885 - val_loss: 0.0337 - val_accuracy: 0.9903\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 125s 80ms/step - loss: 0.0260 - accuracy: 0.9920 - val_loss: 0.0303 - val_accuracy: 0.9921\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 117s 75ms/step - loss: 0.0283 - accuracy: 0.9916 - val_loss: 0.0298 - val_accuracy: 0.9914\n",
      "Epoch 13/100\n",
      " 636/1563 [===========>..................] - ETA: 1:07 - loss: 0.0219 - accuracy: 0.9935"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 121s 78ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 0.0378 - val_accuracy: 0.9925\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.0235 - accuracy: 0.9929 - val_loss: 0.0276 - val_accuracy: 0.9937\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.0227 - accuracy: 0.9929 - val_loss: 0.0317 - val_accuracy: 0.9930\n",
      "Epoch 17/100\n",
      "1069/1563 [===================>..........] - ETA: 35s - loss: 0.0205 - accuracy: 0.9936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.0224 - accuracy: 0.9930 - val_loss: 0.0302 - val_accuracy: 0.9931\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 130s 83ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.0374 - val_accuracy: 0.9921\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 147s 94ms/step - loss: 0.0220 - accuracy: 0.9930 - val_loss: 0.0343 - val_accuracy: 0.9932\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.0301 - val_accuracy: 0.9933\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 139s 89ms/step - loss: 0.0211 - accuracy: 0.9937 - val_loss: 0.0378 - val_accuracy: 0.9923\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.0309 - val_accuracy: 0.9936\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 128s 82ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.0324 - val_accuracy: 0.9933\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 142s 91ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.0382 - val_accuracy: 0.9928\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 148s 94ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.0372 - val_accuracy: 0.9935\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 135s 87ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.0360 - val_accuracy: 0.9927\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 161s 103ms/step - loss: 0.0214 - accuracy: 0.9940 - val_loss: 0.0338 - val_accuracy: 0.9928\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 152s 97ms/step - loss: 0.0205 - accuracy: 0.9940 - val_loss: 0.0311 - val_accuracy: 0.9936\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 143s 91ms/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.0312 - val_accuracy: 0.9935\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 129s 83ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0345 - val_accuracy: 0.9940\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 153s 98ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0325 - val_accuracy: 0.9932\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 156s 100ms/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.0320 - val_accuracy: 0.9938\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 138s 88ms/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 0.0445 - val_accuracy: 0.9931\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.0228 - accuracy: 0.9941 - val_loss: 0.0342 - val_accuracy: 0.9923\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 135s 86ms/step - loss: 0.0200 - accuracy: 0.9944 - val_loss: 0.0430 - val_accuracy: 0.9930\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 166s 106ms/step - loss: 0.0196 - accuracy: 0.9949 - val_loss: 0.0360 - val_accuracy: 0.9941\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 155s 99ms/step - loss: 0.0156 - accuracy: 0.9955 - val_loss: 0.0573 - val_accuracy: 0.9907\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 135s 86ms/step - loss: 0.0216 - accuracy: 0.9940 - val_loss: 0.0404 - val_accuracy: 0.9936\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.0367 - val_accuracy: 0.9932\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.0201 - accuracy: 0.9941 - val_loss: 0.0447 - val_accuracy: 0.9929\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.0190 - accuracy: 0.9946 - val_loss: 0.0384 - val_accuracy: 0.9931\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.0188 - accuracy: 0.9946 - val_loss: 0.0421 - val_accuracy: 0.9932\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 136s 87ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 0.0456 - val_accuracy: 0.9932\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.0181 - accuracy: 0.9949 - val_loss: 0.0366 - val_accuracy: 0.9943\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 142s 91ms/step - loss: 0.0215 - accuracy: 0.9941 - val_loss: 0.0427 - val_accuracy: 0.9932\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 145s 93ms/step - loss: 0.0192 - accuracy: 0.9946 - val_loss: 0.0530 - val_accuracy: 0.9919\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 143s 92ms/step - loss: 0.0199 - accuracy: 0.9948 - val_loss: 0.0396 - val_accuracy: 0.9930\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.0213 - accuracy: 0.9943 - val_loss: 0.0459 - val_accuracy: 0.9941\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 147s 94ms/step - loss: 0.0187 - accuracy: 0.9952 - val_loss: 0.0404 - val_accuracy: 0.9933\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 161s 103ms/step - loss: 0.0207 - accuracy: 0.9947 - val_loss: 0.0318 - val_accuracy: 0.9943\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 152s 97ms/step - loss: 0.0211 - accuracy: 0.9943 - val_loss: 0.0431 - val_accuracy: 0.9934\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 153s 98ms/step - loss: 0.0182 - accuracy: 0.9949 - val_loss: 0.0523 - val_accuracy: 0.9924\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 156s 100ms/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 0.0524 - val_accuracy: 0.9930\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.0209 - accuracy: 0.9944 - val_loss: 0.0397 - val_accuracy: 0.9941\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 155s 99ms/step - loss: 0.0213 - accuracy: 0.9946 - val_loss: 0.0465 - val_accuracy: 0.9925\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 151s 97ms/step - loss: 0.0213 - accuracy: 0.9948 - val_loss: 0.0315 - val_accuracy: 0.9940\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.0201 - accuracy: 0.9948 - val_loss: 0.0504 - val_accuracy: 0.9922\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 137s 87ms/step - loss: 0.0206 - accuracy: 0.9949 - val_loss: 0.0387 - val_accuracy: 0.9944\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.0372 - val_accuracy: 0.9949\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 143s 92ms/step - loss: 0.0213 - accuracy: 0.9948 - val_loss: 0.0465 - val_accuracy: 0.9929\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.0231 - accuracy: 0.9944 - val_loss: 0.0367 - val_accuracy: 0.9936\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 146s 93ms/step - loss: 0.0186 - accuracy: 0.9949 - val_loss: 0.0389 - val_accuracy: 0.9939\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.0222 - accuracy: 0.9944 - val_loss: 0.0483 - val_accuracy: 0.9928\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 143s 92ms/step - loss: 0.0200 - accuracy: 0.9941 - val_loss: 0.0421 - val_accuracy: 0.9930\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 138s 88ms/step - loss: 0.0198 - accuracy: 0.9948 - val_loss: 0.0424 - val_accuracy: 0.9939\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.0230 - accuracy: 0.9943 - val_loss: 0.0448 - val_accuracy: 0.9941\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 155s 99ms/step - loss: 0.0204 - accuracy: 0.9949 - val_loss: 0.0439 - val_accuracy: 0.9941\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 173s 110ms/step - loss: 0.0169 - accuracy: 0.9956 - val_loss: 0.0446 - val_accuracy: 0.9935\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 139s 89ms/step - loss: 0.0210 - accuracy: 0.9946 - val_loss: 0.0421 - val_accuracy: 0.9937\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 160s 103ms/step - loss: 0.0225 - accuracy: 0.9942 - val_loss: 0.0499 - val_accuracy: 0.9928\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 0.0411 - val_accuracy: 0.9926\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 142s 91ms/step - loss: 0.0213 - accuracy: 0.9943 - val_loss: 0.0442 - val_accuracy: 0.9942\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 165s 105ms/step - loss: 0.0274 - accuracy: 0.9935 - val_loss: 0.0411 - val_accuracy: 0.9935\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 159s 102ms/step - loss: 0.0192 - accuracy: 0.9952 - val_loss: 0.0436 - val_accuracy: 0.9940\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 143s 91ms/step - loss: 0.0237 - accuracy: 0.9934 - val_loss: 0.0454 - val_accuracy: 0.9941\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 147s 94ms/step - loss: 0.0209 - accuracy: 0.9945 - val_loss: 0.0505 - val_accuracy: 0.9936\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 148s 95ms/step - loss: 0.0205 - accuracy: 0.9951 - val_loss: 0.0583 - val_accuracy: 0.9929\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 155s 99ms/step - loss: 0.0207 - accuracy: 0.9949 - val_loss: 0.0581 - val_accuracy: 0.9931\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 156s 100ms/step - loss: 0.0217 - accuracy: 0.9950 - val_loss: 0.0515 - val_accuracy: 0.9930\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 222s 142ms/step - loss: 0.0232 - accuracy: 0.9943 - val_loss: 0.0497 - val_accuracy: 0.9937\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 229s 146ms/step - loss: 0.0236 - accuracy: 0.9942 - val_loss: 0.0550 - val_accuracy: 0.9927\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 205s 131ms/step - loss: 0.0237 - accuracy: 0.9943 - val_loss: 0.0504 - val_accuracy: 0.9935\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 183s 117ms/step - loss: 0.0208 - accuracy: 0.9951 - val_loss: 0.0487 - val_accuracy: 0.9931\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 176s 113ms/step - loss: 0.0222 - accuracy: 0.9951 - val_loss: 0.0453 - val_accuracy: 0.9933\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 176s 113ms/step - loss: 0.0227 - accuracy: 0.9945 - val_loss: 0.0403 - val_accuracy: 0.9934\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 177s 113ms/step - loss: 0.0236 - accuracy: 0.9939 - val_loss: 0.0462 - val_accuracy: 0.9938\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 176s 113ms/step - loss: 0.0216 - accuracy: 0.9950 - val_loss: 0.0493 - val_accuracy: 0.9933\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 166s 106ms/step - loss: 0.0216 - accuracy: 0.9948 - val_loss: 0.0375 - val_accuracy: 0.9937\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 159s 102ms/step - loss: 0.0262 - accuracy: 0.9939 - val_loss: 0.0463 - val_accuracy: 0.9938\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 196s 125ms/step - loss: 0.0213 - accuracy: 0.9950 - val_loss: 0.0535 - val_accuracy: 0.9929\n",
      "Epoch 91/100\n",
      "1246/1563 [======================>.......] - ETA: 33s - loss: 0.0249 - accuracy: 0.9945"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "cnn_history = model.fit(X_train_keras, y_train_keras, \n",
    "          validation_data=(X_validation_keras, y_validation_keras), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38757b03-e18f-4728-ac91-ace430c939ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View keys\n",
    "print(cnn_history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95038bd-c72f-422f-b1e6-98dd765c10ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracy of CNN\n",
    "print(\"CNN Final Accuracy\", cnn_history.history['accuracy'][-1])\n",
    "pd.Series(cnn_history.history['accuracy']).plot(logy=False)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d1ce26-7fd3-4763-a9a2-45a494806aaa",
   "metadata": {},
   "source": [
    "**Deep Convolutional Generative Adversarial Network (DCGAN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee0197-86ff-4366-9e55-d1b97977e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to develop model\n",
    "class ElapsedTimer(object):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "    def elapsed(self,sec):\n",
    "        if sec < 60:\n",
    "            return str(sec) + \" sec\"\n",
    "        elif sec < (60 * 60):\n",
    "            return str(sec / 60) + \" min\"\n",
    "        else:\n",
    "            return str(sec / (60 * 60)) + \" hr\"\n",
    "    def elapsed_time(self):\n",
    "        print(\"Elapsed: %s \" % self.elapsed(time.time() - self.start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf6dae1-43b2-42ca-8b27-fb43404e5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(object):\n",
    "    def __init__(self, img_rows=28, img_cols=28, channel=1):\n",
    "\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channel = channel\n",
    "        self.D = None   # discriminator\n",
    "        self.G = None   # generator\n",
    "        self.AM = None  # adversarial model\n",
    "        self.DM = None  # discriminator model\n",
    "        \n",
    "    def generator(self, depth=256, dim=7, dropout=0.3, momentum=0.8, \\\n",
    "                  window=5, input_dim=100, output_depth=1):\n",
    "        if self.G:\n",
    "            return self.G\n",
    "        self.G = Sequential()\n",
    "        self.G.add(Dense(dim*dim*depth, input_dim=input_dim))\n",
    "        self.G.add(BatchNormalization(momentum=momentum))\n",
    "        self.G.add(Activation('relu'))\n",
    "        self.G.add(Reshape((dim, dim, depth)))\n",
    "        self.G.add(Dropout(dropout))\n",
    "        \n",
    "        self.G.add(UpSampling2D())\n",
    "        self.G.add(Conv2DTranspose(int(depth/2), window, padding='same'))\n",
    "        self.G.add(BatchNormalization(momentum=momentum))\n",
    "        self.G.add(Activation('relu'))\n",
    "\n",
    "        self.G.add(UpSampling2D())\n",
    "        self.G.add(Conv2DTranspose(int(depth/4), window, padding='same'))\n",
    "        self.G.add(BatchNormalization(momentum=momentum))\n",
    "        self.G.add(Activation('relu'))\n",
    "\n",
    "        self.G.add(Conv2DTranspose(int(depth/8), window, padding='same'))\n",
    "        self.G.add(BatchNormalization(momentum=momentum))\n",
    "        self.G.add(Activation('relu'))\n",
    "\n",
    "        self.G.add(Conv2DTranspose(output_depth, window, padding='same'))\n",
    "        self.G.add(Activation('sigmoid'))\n",
    "        self.G.summary()\n",
    "        return self.G\n",
    "\n",
    "    def discriminator(self, depth=64, dropout=0.3, alpha=0.3):\n",
    "        if self.D:\n",
    "            return self.D\n",
    "        self.D = Sequential()\n",
    "        input_shape = (self.img_rows, self.img_cols, self.channel)\n",
    "        self.D.add(Conv2D(depth*1, 5, strides=2, input_shape=input_shape,\n",
    "            padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=alpha))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv2D(depth*2, 5, strides=2, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=alpha))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv2D(depth*4, 5, strides=2, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=alpha))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv2D(depth*8, 5, strides=1, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=alpha))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Flatten())\n",
    "        self.D.add(Dense(1))\n",
    "        self.D.add(Activation('sigmoid'))\n",
    "        self.D.summary()\n",
    "        return self.D\n",
    "\n",
    "    def discriminator_model(self):\n",
    "        if self.DM:\n",
    "            return self.DM\n",
    "        optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
    "        self.DM = Sequential()\n",
    "        self.DM.add(self.discriminator())\n",
    "        self.DM.compile(loss='binary_crossentropy', \\\n",
    "                        optimizer=optimizer, metrics=['accuracy'])\n",
    "        return self.DM\n",
    "\n",
    "    def adversarial_model(self):\n",
    "        if self.AM:\n",
    "            return self.AM\n",
    "        optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
    "        self.AM = Sequential()\n",
    "        self.AM.add(self.generator())\n",
    "        self.AM.add(self.discriminator())\n",
    "        self.AM.compile(loss='binary_crossentropy', \\\n",
    "                        optimizer=optimizer, metrics=['accuracy'])\n",
    "        return self.AM\n",
    "        \n",
    "class MNIST_DCGAN(object):\n",
    "    def __init__(self, x_train):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channel = 1\n",
    "\n",
    "        self.x_train = x_train\n",
    "\n",
    "        self.DCGAN = DCGAN()\n",
    "        self.discriminator =  self.DCGAN.discriminator_model()\n",
    "        self.adversarial = self.DCGAN.adversarial_model()\n",
    "        self.generator = self.DCGAN.generator()\n",
    "\n",
    "    def train(self, train_steps=2000, batch_size=256, save_interval=0):\n",
    "        noise_input = None\n",
    "        if save_interval>0:\n",
    "            noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "        for i in range(train_steps):\n",
    "            images_train = self.x_train[np.random.randint(0,\n",
    "                self.x_train.shape[0], size=batch_size), :, :, :]\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            images_fake = self.generator.predict(noise)\n",
    "            x = np.concatenate((images_train, images_fake))\n",
    "            y = np.ones([2*batch_size, 1])\n",
    "            y[batch_size:, :] = 0\n",
    "            \n",
    "            d_loss = self.discriminator.train_on_batch(x, y)\n",
    "\n",
    "            y = np.ones([batch_size, 1])\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            a_loss = self.adversarial.train_on_batch(noise, y)\n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], \\\n",
    "                                                      a_loss[1])\n",
    "            print(log_mesg)\n",
    "            if save_interval>0:\n",
    "                if (i+1)%save_interval==0:\n",
    "                    self.plot_images(save2file=True, \\\n",
    "                        samples=noise_input.shape[0],\\\n",
    "                        noise=noise_input, step=(i+1))\n",
    "\n",
    "    def plot_images(self, save2file=False, fake=True, samples=16, \\\n",
    "                    noise=None, step=0):\n",
    "        current_path = os.getcwd()\n",
    "        file = os.path.sep.join(['', 'images', 'chapter12', 'synthetic_mnist', ''])\n",
    "        filename = 'mnist.png'\n",
    "        if fake:\n",
    "            if noise is None:\n",
    "                noise = np.random.uniform(-1.0, 1.0, size=[samples, 100])\n",
    "            else:\n",
    "                filename = \"mnist_%d.png\" % step\n",
    "            images = self.generator.predict(noise)\n",
    "        else:\n",
    "            i = np.random.randint(0, self.x_train.shape[0], samples)\n",
    "            images = self.x_train[i, :, :, :]\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i in range(images.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            image = images[i, :, :, :]\n",
    "            image = np.reshape(image, [self.img_rows, self.img_cols])\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        if save2file:\n",
    "            plt.savefig(current_path+file+filename)\n",
    "            plt.close('all')\n",
    "        else:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b41db8-3216-4108-9069-19da11fcbc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MNIST DCGAN and train\n",
    "mnist_dcgan = MNIST_DCGAN(X_train_keras)\n",
    "timer = ElapsedTimer()\n",
    "mnist_dcgan.train(train_steps=10000, batch_size=256, save_interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37376cfa-af46-4abd-bf2a-668262f50399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batch of synthetic MNIST images\n",
    "timer.elapsed_time()\n",
    "mnist_dcgan.plot_images(fake=True)\n",
    "mnist_dcgan.plot_images(fake=False, save2file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9492c51-9e42-46e1-b6be-1c66768643a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "print(\"Completed: \", dt.datetime.now())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
